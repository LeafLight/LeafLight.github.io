<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>LeafLight&#39;s Blog by Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="LeafLight&#39;s Blog by Hexo">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="LeafLight&#39;s Blog by Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="LeafLight">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="LeafLight&#39;s Blog by Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.2"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">LeafLight&#39;s Blog by Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-EntropyAndCrossEntropy" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/08/09/EntropyAndCrossEntropy/" class="article-date">
  <time datetime="2022-08-08T17:51:44.727Z" itemprop="datePublished">2022-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/08/09/EntropyAndCrossEntropy/">An interesting understanding of Entropy and Cross Entropy</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="What-is-Entropy-What-is-Information-Entropy-What-is-the-difference-between-them"><a href="#What-is-Entropy-What-is-Information-Entropy-What-is-the-difference-between-them" class="headerlink" title="What is Entropy? What is Information Entropy? What is the difference between them?"></a>What is Entropy? What is Information Entropy? What is the difference between them?</h2><p>When learning the <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1US4t1M7g?p=48">Pytorch turorial from Bilibili</a>, the appearance of entropy and its abstract definition really confused me.</p>
<p>Here is the answer for entropy from Encyclopedia Britannica:</p>
<blockquote>
<p>Entropy, the measure of a system’s thermal energy per unit temperature that is unavailable for doing useful work.</p>
</blockquote>
<p>Here is the answer for infromation entropy from wiki:</p>
<blockquote>
<p>In information theory, the entropy of a random variable is the average level of “information”, “surprise”, or “uncertainty” inherent to the variable’s possible outcomes.</p>
</blockquote>
<p>These definitions above may do not help at all. And the simple answer of the difference between them is that they are just the same thing in different fields.</p>
<h2 id="Why-do-we-use-Information-Entropy"><a href="#Why-do-we-use-Information-Entropy" class="headerlink" title="Why do we use Information Entropy?"></a>Why do we use Information Entropy?</h2><p>When faced with classification problems(or sometimes logistic regression), using Information Entropy instead of final accuracy as loss is important. (though it seems like we use entropy because of the weakness of using final accuracy instead of the strength of information entropy,2022/2/21)<br>(2022/2/22, I saw the power of cross entropy in the field of classification in a <a target="_blank" rel="noopener" href="https://leaflight.github.io/2022/02/26/CNN_practice_WorkFlow/">practice of CNN work for MNIST</a>.)</p>
<p>That is because the output of a classification model are usually a list of transformed(or cutted) probabilities(like p&gt;0.5?t=1:t=0), which means using the final accuracy will lead to some problems,such as:</p>
<ul>
<li>the accuracy remains unchanged when the Weights of a net work are changed.(e.g., p changed from 0.3 to 0.4, but it doesn’t help)</li>
<li>the gradient is not continuous since the accuracy is not continuous.</li>
</ul>
<p>(Here I wondered that why not use MSE of p and 0 or 1 as loss, and then I learned that it does work(Actually, this method is used in <a target="_blank" rel="noopener" href="https://leaflight.github.io/2022/02/17/ClassificationAndMNIST/">the MNIST test before</a>). No one can tell which one is better than another. But it is an interesting way to understand information, and a useful way to evaluate the loss, so just go on.)</p>
<h2 id="how-to-understand-Information-Entropy-in-a-easy-way"><a href="#how-to-understand-Information-Entropy-in-a-easy-way" class="headerlink" title="how to understand Information Entropy in a easy way?"></a>how to understand Information Entropy in a easy way?</h2><p>To understand a math definition, usually the combination of its actual math fomula and a scene leading-in will help.</p>
<h3 id="The-math-formula-of-Information-Entropy"><a href="#The-math-formula-of-Information-Entropy" class="headerlink" title="The math formula of Information Entropy"></a>The math formula of Information Entropy</h3><p>H(p) = -sum(p.i * log(p.i))</p>
<p>note:</p>
<ul>
<li>p: p.1, p.2, …, p.n</li>
<li>the base of log can be any number when comparing the H() of different samples.</li>
</ul>
<h3 id="Scene-leading-in"><a href="#Scene-leading-in" class="headerlink" title="Scene leading-in"></a>Scene leading-in</h3><p>Reference: <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ga41127Zu">Bilibili</a><br>Let’s imagine a scene that a dice is thrown and we don’t know the number of the up face. Here are 3 pieces of information:</p>
<ol>
<li>The number is larger than 0</li>
<li>The number is larger than 3</li>
<li>The number is larger than 5</li>
</ol>
<p>It is obvious that the third information is most valuable.So it is possible to compare the value of different information. But we want to evaluate the value of information by quantity. So let’s imagine another scene of a ball-number-guessing game. In this game, there are <em>n</em> balls in a box,which all have a number on it surface from 1 to n. One of them will picked out, and we need to guess the number on it, or we can to pay 1 dollar for asking for a question about whether the it is larger than a certain number. We all know dichotomy is the best way if we are willing to pay for the answer:</p>
<ol>
<li>When there 2 balls,we need to ask 1 time,because 2&lt;2^2</li>
<li>When there 4 balls,we need to ask 2 times,because 4&lt;2^3</li>
<li>When there 8 balls ,we need to ask 3 times,because 8&lt;2^4</li>
</ol>
<p>So if we can see the number of the ball directly, we can:</p>
<ol>
<li>save 1 dollar</li>
<li>save 2 dollars</li>
<li>save 3 dollars</li>
</ol>
<p>Then we learned that the value of the information about what the number of the ball is depends on the probability that we can guess it. In another way, the information’s value depends on probability we get the accurate answer without the information.</p>
<p>And we can be more mathematical, in this scene, the value of the information can be calculated by the formula below:<br><code>value = -log2(p)</code><br>note: “2” here is the information unit</p>
<p>We can find that the more uncertainty the information can clear, the more value the information has.</p>
<p>But we what we need to understand is informatiom entropy, so let’s imagine anthor scene:<br>It is still a game about balls, but this time there are only a white ball and a black ball in the box.And <em>Pw</em> is the probability of picking out the white ball,while <em>Pb</em> is for the black one. We guess the ball is black. Fortunately, your friend saw the ball’s color, and he said:</p>
<ol>
<li>The ball is black</li>
<li>The ball is white</li>
</ol>
<p>This friend’s sight is good.So in which condition, he helps us more?<br>As we learned before, we can evaluate the information’s value by quantity. So:</p>
<ol>
<li>-log2(Pb)</li>
<li>-log2(Pw)<br>note:”2” here is not very important because it doesn’t matter when we just want to compare two value</li>
</ol>
<p>This comparison is in sense because if the <em>Pb = 0.9</em>, we can guess it by ourselve more easily, which means the information of this friend seems not very valuable.<br>Now, what is the average value of information given by this friend?</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a_value = -sum(p.i*log(p.i))</span><br></pre></td></tr></table></figure>

<p>Amazing, it is the formula of Entropy. The more chaos the system is, the more average value of a accurate information has, so it makes sense!</p>
<h2 id="Cross-Entropy"><a href="#Cross-Entropy" class="headerlink" title="Cross Entropy"></a>Cross Entropy</h2><p>The same as <em>Information Entropy</em>, there is a mathematical formula and  scene leading-in for <em>Cross Entropy</em></p>
<h3 id="Formula"><a href="#Formula" class="headerlink" title="Formula"></a>Formula</h3><p>H(p,q) = -sum(p.i * log(q.i))</p>
<h3 id="Scene-leading-in-1"><a href="#Scene-leading-in-1" class="headerlink" title="Scene leading-in"></a>Scene leading-in</h3><p>Here we need to know that Information Entropy can be used to stand the shortest encoding length of a system.For example, To encoing a system of A,B,C,D(their probabilities are 1/2,1/4,1/8,1/8 respectively) Then the shortest average encoding length of this system is H = 1/2 * 1 + 1/4 * 2 + 1/8 * 3 + 1/8 * 3 = 1.75.<br>So if the p.i, which is given by prediction, is equal to q.i, the cross entropy is equal to entropy of q, otherwise the cross entropy will be larger than entropy.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/08/09/EntropyAndCrossEntropy/" data-id="cl6l23unt0004bp26cw1a53os" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Entropy/" rel="tag">Entropy</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Information-theory/" rel="tag">Information theory</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Note/" rel="tag">Note</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-CNN_practice_WorkFlow" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/08/09/CNN_practice_WorkFlow/" class="article-date">
  <time datetime="2022-08-08T17:51:44.726Z" itemprop="datePublished">2022-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/08/09/CNN_practice_WorkFlow/">CNN Practice Workflow</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Convolution Neural Network is a widely used model all around the world. To have a more profound understanding of it and promote my programming skills with python in a class-style way, I decide to train a CNN used to recognize hand-writing numbers by <em>MNIST</em> dataset.</p>
<h2 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow"></a>Workflow</h2><ol>
<li>Loading the MNIST data into 2 sets(train, test)</li>
<li>Building a CNN, which has a structure of <del>4 layers (2 Convolution layers, 2 fully connected layers)</del>  8 layers(4 Convolution layers, 4 linear full connected layers)</li>
<li>Training the network by train set</li>
<li>Choosing the parameters by validation set</li>
<li>Testing by test set</li>
<li>Polishing the network by some tricks(e.g., dropout, pooling, regularization)<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2>In this practice, I learned many things that wouldn’t be learned just from listenning to online courses.</li>
<li>Figure out how <code>optim</code>, <code>nn.Sequential</code> and some other classes or functions work.</li>
<li>Realize how vital the parameters are for the network(<em>I trained a network with the test acc. of approximately 10% with the help of a learning rate of 0.001, which made me lol</em>)</li>
<li>It surprised me that the network’s performance was promoted much more greatly when I just change the <code>criterion</code> of loss from <code>nn.MSELoss</code> to <code>nn.CrossEntropyLoss</code>.</li>
</ol>
<h2 id="Something-Important"><a href="#Something-Important" class="headerlink" title="Something Important"></a>Something Important</h2><p>Before actually doing this work code by code, I thought what would impress me most will be the advantage of the CNN. When the result came out, the performance of CNN4 I trained was almost the same as the network with 4 activated linear layers. (~93%,a little higher than the old one’s ~90%)</p>
<p>But something that I didn’t care about made this practice more interesting.Because of some mistakes, I used MSE as loss of the network instead of cross-entropy, which is recommended for classification problems. After solving the mistakes of using cross-entropy and applying it to my new network, it surprised me with its brilliant performance promotion, of which the acc. reached <strong>93%</strong> in the <strong>first</strong> epoch of training. And the final acc. after 8 epochs reached <strong>97%</strong>. It is amazing, because the network of the same structure with MSE has an acc. of about <strong>30%</strong> after the first epoch, and can <strong>rarely</strong> reach 95%.</p>
<p>In a blog about cross entropy I wrote before I said that maybe it is just something interesting but not very important since we have MSE, which it more simple and explicit. I would have to change it right nowwwwww.</p>
<p>It also comes to me that neural network and the mathematics behind it are not as simple as I thought before.(Obviously)</p>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p>The codes below contains the network, along with the loading of MNIST data and the training of it.<br>Some negligiable codes are not presented here.(like <code>one_hot</code>)<br>This one used MSE as loss.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/python3</span></span><br><span class="line"><span class="comment">#-*-coding:UTF-8-*-</span></span><br><span class="line"><span class="comment">#Author:LeafLight</span></span><br><span class="line"><span class="comment">#Date: 2022-02-24</span></span><br><span class="line"><span class="comment">########################################</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> MNIST_utils <span class="keyword">import</span>  one_hot</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="comment"># step1. load dataset</span></span><br><span class="line">batch_size= <span class="number">512</span></span><br><span class="line">dataset_MU = <span class="number">0.1307</span></span><br><span class="line">dataset_SIG = <span class="number">0.3081</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">        torchvision.datasets.MNIST(<span class="string">&#x27;mnist.data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                    transform=torchvision.transforms.Compose([</span><br><span class="line">                                        torchvision.transforms.ToTensor(),</span><br><span class="line">                                        torchvision.transforms.Normalize(</span><br><span class="line">                                            (dataset_MU,),(dataset_SIG,))</span><br><span class="line">                                        ])</span><br><span class="line">        ),</span><br><span class="line">        batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">        torchvision.datasets.MNIST(<span class="string">&#x27;mnist.data/&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                    transform=torchvision.transforms.Compose([</span><br><span class="line">                                        torchvision.transforms.ToTensor(),</span><br><span class="line">                                        torchvision.transforms.Normalize(</span><br><span class="line">                                            (dataset_MU,),(dataset_SIG,))</span><br><span class="line">                                        </span><br><span class="line">                                        ])</span><br><span class="line">        ),</span><br><span class="line">    batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">sample_x, sample_y = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))</span><br><span class="line"><span class="built_in">print</span>(sample_x.shape, sample_y.shape)</span><br><span class="line"><span class="comment">#Output[0]:torch.Size([512, 1, 28, 28]) torch.Size([512])</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#step2. build network</span></span><br><span class="line"><span class="comment">############################################################</span></span><br><span class="line"><span class="comment">#&lt;&lt;&lt; network &lt;&lt;&lt;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN4</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CNN4, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">                <span class="comment">#nn.BatchNorm1d(1),</span></span><br><span class="line">                nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">                nn.Conv2d(<span class="number">6</span>, <span class="number">6</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">                nn.Conv2d(<span class="number">6</span>, <span class="number">6</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),</span><br><span class="line">                nn.Conv2d(<span class="number">6</span>, <span class="number">1</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),</span><br><span class="line">                <span class="comment">#flatten process required,</span></span><br><span class="line">                <span class="comment">#nn.Flatten(start_dim=2, end_dim=3),</span></span><br><span class="line">                nn.Flatten(),</span><br><span class="line">                nn.Linear(<span class="number">784</span>, <span class="number">500</span>),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">                nn.Linear(<span class="number">500</span>, <span class="number">400</span>),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">                nn.Linear(<span class="number">400</span>, <span class="number">200</span>),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">                nn.Linear(<span class="number">200</span>, <span class="number">10</span>),</span><br><span class="line">                )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = self.model(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">net = CNN4()</span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.025</span>, momentum=<span class="number">0.8</span>)</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"><span class="comment">#&gt;&gt;&gt; network &gt;&gt;&gt;</span></span><br><span class="line"><span class="comment">############################################################</span></span><br><span class="line"><span class="comment">#criterion = nn.CrossEntropyLoss()</span></span><br><span class="line">train_loss = []</span><br><span class="line"><span class="comment">#step3. train</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment">#x = x.view(x.size(0), 28*28)</span></span><br><span class="line">        out = net(x)</span><br><span class="line">        y_onehot = one_hot(y)</span><br><span class="line">        loss = criterion(out, y_onehot)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> batch_idx%<span class="number">20</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;epoch: &quot;</span>, epoch,<span class="string">&quot;, batch_idx: &quot;</span>, batch_idx, <span class="string">&quot;, loss: &quot;</span>, loss.data)</span><br><span class="line">        train_loss.append(loss.item())</span><br><span class="line"></span><br><span class="line">    total_correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> idx,(x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">            out = net(x)</span><br><span class="line">            pred = out.argmax(dim=<span class="number">1</span>)</span><br><span class="line">            correct = pred.eq(y).<span class="built_in">sum</span>().<span class="built_in">float</span>()</span><br><span class="line">            total_correct += correct</span><br><span class="line">            <span class="keyword">if</span> idx%<span class="number">100</span> ==<span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;idx: &quot;</span>, idx, <span class="string">&quot;, correct: &quot;</span>, correct)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;pred/num:&quot;</span>, pred[<span class="number">0</span>], y[<span class="number">0</span>])</span><br><span class="line">    total_num = <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;total num: &quot;</span>, total_num)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;total correct: &quot;</span>, total_correct)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;test acc. :&quot;</span>, total_correct/total_num)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>The one using cross-entropy is changed from the script above with modification below.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">73c73</span><br><span class="line">&lt; criterion = nn.MSELoss()</span><br><span class="line">---</span><br><span class="line">&gt; criterion = nn.CrossEntropyLoss()</span><br><span class="line">83,85c83,85</span><br><span class="line">&lt;         out = net(x)</span><br><span class="line">&lt;         y_onehot = one_hot(y)</span><br><span class="line">&lt;         loss = criterion(out, y_onehot)</span><br><span class="line">---</span><br><span class="line">&gt;         logits = net(x)</span><br><span class="line">&gt;         <span class="comment">#y_onehot = one_hot(y)</span></span><br><span class="line">&gt;         loss = criterion(logits, y)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/08/09/CNN_practice_WorkFlow/" data-id="cl6l23unr0001bp26gj6f4185" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MNIST/" rel="tag">MNIST</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Workflow/" rel="tag">Workflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-nltk-Grammar" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/04/16/nltk-Grammar/" class="article-date">
  <time datetime="2022-04-16T13:14:59.000Z" itemprop="datePublished">2022-04-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/MachineLearning/">MachineLearning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/04/16/nltk-Grammar/">nltk and Grammar -- Encoding Part</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>When dealing with the recent project associated with <em>CMap</em>, an interesting neural network model called <strong>GVAE</strong> caught my attention. After learning the details of it, I tried to re-do the model and this blog is a recording in some ways and mainly about the <em>Grammar</em> part.</p>
<h2 id="Grammar-–-Context-Free-Grammar-CFG"><a href="#Grammar-–-Context-Free-Grammar-CFG" class="headerlink" title="Grammar – Context-Free Grammar(CFG)"></a>Grammar – Context-Free Grammar(CFG)</h2><p>The key feature of GVAE is <strong>CFG</strong>, which can be manipulated easily by the python module <code>nltk</code>.</p>
<ol>
<li><p>Generate a <code>CFG</code> object from string</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> CFG</span><br><span class="line"></span><br><span class="line">SMILEsGrammar = CFG.fromstring(</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    smiles -&gt; chain</span></span><br><span class="line"><span class="string">    atom -&gt; bracket_atom | aliphatic_organic | aromatic_organic</span></span><br><span class="line"><span class="string">    aliphatic_organic -&gt; &#x27;B&#x27; | &#x27;C&#x27; | &#x27;N&#x27; | &#x27;O&#x27; | &#x27;S&#x27; | &#x27;P&#x27; | &#x27;F&#x27; | &#x27;I&#x27; | &#x27;Cl&#x27; | &#x27;Br&#x27;</span></span><br><span class="line"><span class="string">    aromatic_organic -&gt; &#x27;[&#x27; BAI &#x27;]&#x27;</span></span><br><span class="line"><span class="string">    BAI -&gt; isotope symbol BAC | symbol BAC | isotope symbol | symbol</span></span><br><span class="line"><span class="string">    BAC -&gt; chiral BAH | BAH | chiral</span></span><br><span class="line"><span class="string">    BAH -&gt; hcount BACH | BACH | hcount</span></span><br><span class="line"><span class="string">    BACH -&gt; charge class | charge | class</span></span><br><span class="line"><span class="string">    symbol -&gt; aliphatic_organic | aromatic_organic</span></span><br><span class="line"><span class="string">    isotope -&gt; DIGIT | DIGIT DIGIT | DIGIT DIGIT DIGIT</span></span><br><span class="line"><span class="string">    DIGIT -&gt; &#x27;1&#x27; | &#x27;2&#x27; | &#x27;3&#x27; | &#x27;4&#x27; | &#x27;5&#x27; | &#x27;6&#x27; | &#x27;7&#x27; | &#x27;8&#x27;</span></span><br><span class="line"><span class="string">    chiral -&gt; &#x27;@&#x27; | &#x27;@@&#x27;</span></span><br><span class="line"><span class="string">    hcount -&gt; &#x27;H&#x27; | &#x27;H&#x27; DIGIT</span></span><br><span class="line"><span class="string">    charge -&gt; &#x27;-&#x27; | &#x27;-&#x27; DIGIT | &#x27;-&#x27; DIGIT DIGIT | &#x27;+&#x27; | &#x27;+&#x27; DIGIT | &#x27;+&#x27; DIGIT DIGIT</span></span><br><span class="line"><span class="string">    bond -&gt; &#x27;-&#x27; | &#x27;=&#x27; | &#x27;#&#x27; | &#x27;/&#x27; | &#x27;\\&#x27;</span></span><br><span class="line"><span class="string">    ringbond -&gt; DIGIT | bond DIGIT</span></span><br><span class="line"><span class="string">    branched_atom -&gt; atom | atom RB | atom BB | atom RB BB</span></span><br><span class="line"><span class="string">    RB -&gt; RB ringbond | ringbond</span></span><br><span class="line"><span class="string">    BB -&gt; BB branch | branch</span></span><br><span class="line"><span class="string">    branch -&gt; &#x27;(&#x27; chain &#x27;)&#x27; | &#x27;(&#x27; bond chain &#x27;)&#x27;</span></span><br><span class="line"><span class="string">    chain -&gt; branched_atom | chain branched_atom | chain bond branched_atom</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>Generate a parse tree of a molecule in the form of SMILEs</p>
<ol>
<li>Get a tokenizer<br> Since some leaves in the grammar has more than one charactor(like “Cl” or “Br”), default tokenizer may result in errors. <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_zinc_tokenizer</span>(<span class="params">cfg</span>):</span></span><br><span class="line">    <span class="comment"># get all the long tokens for the following replacement work</span></span><br><span class="line">    <span class="comment"># long tokens: tokens with more than one charactor, like &#x27;Br&#x27;</span></span><br><span class="line">    long_tokens = [a <span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">list</span>(SMILEsGrammar._lexical_index.keys()) <span class="keyword">if</span> xlength(a) &gt; <span class="number">1</span>]</span><br><span class="line">    <span class="comment"># char used for replacements of &#x27;Cl&#x27;, &#x27;Br&#x27;, &#x27;@@&#x27;</span></span><br><span class="line">    replacements = [<span class="string">&#x27;$&#x27;</span>, <span class="string">&#x27;%&#x27;</span>, <span class="string">&#x27;^&#x27;</span>]</span><br><span class="line">    <span class="comment"># ensure that we have  paired origin tokens and their replacements</span></span><br><span class="line">    <span class="keyword">assert</span> xlength(long_tokens) == <span class="built_in">len</span>(replacements)</span><br><span class="line">    <span class="comment"># ensure that all the tokens for replacement is available: not in the origin dict of grammar</span></span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> replacements:</span><br><span class="line">        <span class="keyword">assert</span> token <span class="keyword">not</span> <span class="keyword">in</span> cfg._lexical_index</span><br><span class="line"></span><br><span class="line">    <span class="comment"># the func to return</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize</span>(<span class="params">smiles</span>):</span></span><br><span class="line">        <span class="comment"># replace all the long_tokens in the input SMILEs</span></span><br><span class="line">        <span class="keyword">for</span> i, token <span class="keyword">in</span> <span class="built_in">enumerate</span>(long_tokens):</span><br><span class="line">            smiles = smiles.replace(token, replacements[i])</span><br><span class="line">        <span class="comment"># the result variable init</span></span><br><span class="line">        tokens = []</span><br><span class="line">        <span class="keyword">for</span> token <span class="keyword">in</span> smiles:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="comment"># try to find the replaced elements&#x27; index and append the original elements </span></span><br><span class="line">                ix = replacements.index(token)</span><br><span class="line">                tokens.append(long_tokens[ix])</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                tokens.append(token)</span><br><span class="line">        <span class="keyword">return</span> tokens</span><br><span class="line">    <span class="keyword">return</span> tokenize</span><br></pre></td></tr></table></figure></li>
<li>tokenize the SMILEs string<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">smi = <span class="string">&quot;CC1=CC(=O)C2=C(O1)C=C3C(=C2OC)C=CO3&quot;</span></span><br><span class="line">SMILEs_tokenizer = get_zinc_tokenizer(SMILEsGrammar)</span><br><span class="line">smi_t = SMILEs_tokenizer(smi)</span><br></pre></td></tr></table></figure></li>
<li>generate the parse tree of the given SMILEs string<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SMILEs_parser = nltk.ChartParser(SMILEsGrammar)</span><br><span class="line">smi_s = <span class="built_in">next</span>(SMILEs_parser.parse(smi_t))</span><br><span class="line"><span class="built_in">type</span>(smi_s)</span><br><span class="line"><span class="comment"># nltk.tree.tree.Tree</span></span><br></pre></td></tr></table></figure></li>
<li>regenerate the SMILEs from the tree<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;</span>.join(smi_s.leaves()</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>Get the productions-index map dict for one-hot encode</p>
<ol>
<li>productions of the parse tree<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">smi_s.productions()</span><br></pre></td></tr></table></figure></li>
<li>productions-index map dict<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Prod_map = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> ix, prod <span class="keyword">in</span> <span class="built_in">enumerate</span>(SMILEsGrammar.productions()):</span><br><span class="line">	Prod_map[prod] = ix</span><br></pre></td></tr></table></figure></li>
<li>one-hot encoding<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># a batch of smiles strings as example</span></span><br><span class="line">smiles = <span class="string">&quot;here is a list of smiles&quot;</span></span><br><span class="line"></span><br><span class="line">smiles_t = <span class="built_in">map</span>(SMILEs_tokenizer, smiles)</span><br><span class="line"></span><br><span class="line">smiles_parse_trees = []</span><br><span class="line"><span class="keyword">for</span> i, t <span class="keyword">in</span> <span class="built_in">enumerate</span>(smiles_t):</span><br><span class="line">	smiles_parse_trees[i] = SMILEs_parser.parse(t)</span><br><span class="line"></span><br><span class="line">productions_seq = [tree.productions() <span class="keyword">for</span> tree <span class="keyword">in</span> smiles_parse_trees]</span><br><span class="line"></span><br><span class="line">indices = [np.array([Prod_map[prod] <span class="keyword">for</span> prod <span class="keyword">in</span> entry], dtype=<span class="built_in">int</span>) <span class="keyword">for</span> entry <span class="keyword">in</span> productions_seq]</span><br><span class="line"></span><br><span class="line">MAX_LEN = <span class="number">277</span></span><br><span class="line">n_char = <span class="built_in">len</span>(SMILEsGrammar.productions())</span><br><span class="line"></span><br><span class="line"><span class="comment"># init </span></span><br><span class="line">one_hot = np.zeros((<span class="built_in">len</span>(indices), MAX_LEN, n_char),dtype=np.float32)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(indices)):</span><br><span class="line">	num_productions = <span class="built_in">len</span>(indices[i])</span><br><span class="line">	<span class="keyword">if</span> num_productions &gt; MAX_LEN:</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;Too Large molecule, out of range&quot;</span>)</span><br><span class="line">		one_hot[i][np.arange(MAX_LEN), indices[i][:MAX_LEN]] = <span class="number">1</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		one_hot[i][np.arange(num_productions), indices[i]] = <span class="number">1</span></span><br><span class="line">		one_hot[i][np.arange(num_productions, MAX_LEN, -<span class="number">1</span>)] = <span class="number">1</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/04/16/nltk-Grammar/" data-id="cl6l23unx000jbp266s2ra4s2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CMap/" rel="tag">CMap</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GrammarVAE/" rel="tag">GrammarVAE</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MachineLearning/" rel="tag">MachineLearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/molecules/" rel="tag">molecules</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/nltk/" rel="tag">nltk</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-xlength-interesting-function" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/04/10/xlength-interesting-function/" class="article-date">
  <time datetime="2022-04-10T06:26:26.000Z" itemprop="datePublished">2022-04-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/04/10/xlength-interesting-function/">xlength-an interesting function</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>When reading the source code of <a target="_blank" rel="noopener" href="https://github.com/kekegg/DLEPS/bolb/main/code/Preprocess/preprocess.ipynb">DLEPS</a>, some interesting codes caught my eyes, including: <code>six.string_types</code>, <code>get_zinc_tokenizer()</code>, <code>xlength()</code>, and so on.</p>
<h2 id="Main"><a href="#Main" class="headerlink" title="Main"></a>Main</h2><h3 id="Pre-knowledge"><a href="#Pre-knowledge" class="headerlink" title="Pre-knowledge"></a>Pre-knowledge</h3><h4 id="lambda"><a href="#lambda" class="headerlink" title="lambda"></a>lambda</h4><p>A lambda function in <em>python</em> is in some ways like a simple <code>def</code> fucntion with only a <code>return</code> line.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># use `def` function to represent `lambda x: x * x`</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x</span>):</span></span><br><span class="line">	<span class="keyword">return</span> x * x</span><br></pre></td></tr></table></figure>

<h4 id="functools-reduce"><a href="#functools-reduce" class="headerlink" title="functools.reduce()"></a>functools.reduce()</h4><p><code>functools</code> is a python module which contains some advanced functions. The <code>functools.reduce()</code> will apply a given function to a iterable sequence and a initial value is optional.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># use `functools.reduce()` to realize `sum()`</span></span><br><span class="line"><span class="comment"># functools.reduce(func, iter[, init])</span></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line">y = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="built_in">sum</span> = reduce(<span class="keyword">lambda</span> x1, x2: x1 + x2, y, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>)</span><br><span class="line"><span class="comment"># 6</span></span><br></pre></td></tr></table></figure>
<p>In the case above, the first step of work by <code>reduce</code> is to apply the given function with <code>init</code> 0  and the first element of the <code>iter</code> y as input(so the given function must receive 2 parameters) to get the result 1. Then apply the function with the result 1 and the second element 2, and repeat it until the last one of the list.</p>
<p>If no <code>init</code> was given, it would first apply the given function with the first two elements of the <code>iter</code> y.</p>
<h3 id="xlength"><a href="#xlength" class="headerlink" title="xlength()"></a>xlength()</h3><p>The source code of xlength:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xlength</span>(<span class="params">y</span>):</span></span><br><span class="line">	<span class="keyword">return</span> reduce(<span class="keyword">lambda</span> <span class="built_in">sum</span>, element: <span class="built_in">sum</span> + <span class="number">1</span>, y, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>It really confused me when I first ran this code and found that it returns the length of the list. Then I realized it that it works by the interesting applying of <code>init</code> and <code>func</code>. The <code>func</code> desert the <code>element</code>, which means it has no effect on the results the <code>func</code> returns. So the <code>sum</code> is in some ways a counter to count the length of the <code>iter</code> by <code>sum + 1</code> </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/04/10/xlength-interesting-function/" data-id="cl6l23unx000qbp26d71zd8tn" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/functools/" rel="tag">functools</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/lambdaFunction/" rel="tag">lambdaFunction</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-sharement-of-paremeters-between-shell-scripts" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/02/07/sharement-of-paremeters-between-shell-scripts/" class="article-date">
  <time datetime="2022-02-07T05:51:05.000Z" itemprop="datePublished">2022-02-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/02/07/sharement-of-paremeters-between-shell-scripts/">sharement of paremeters between shell scripts</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h1><p>Today some problem occurs when I want to write a shell script that helps me <code>cd</code> to some deep directories which are long enough for me, a lazy man, to write a script. I found that <code>cd</code> does’t work in a <code>.sh</code> file when I use <code>bash</code> to execute it. Then I learned that a child shell is created to execute the commands in the scripts when using <code>bash</code>. To solve this problem, the most fundmental way is to use <code>source</code>, which won’t create a child shell.</p>
<p>After solving it, I wondered that how does two shell scripts share their parameters when one script will create a child shell in another’s child shell, which means that you can’t just use <code>bash config.sh</code> to tell the parent shell what the paraments in the <code>config.sh</code> are, and using <code>source config.sh</code> won’t tell the parent shell’s another child shell(e.g. step1.sh) what the paraments are.(like stucture below) </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#in the `parent.sh`</span></span><br><span class="line"><span class="built_in">source</span> config.sh</span><br><span class="line"></span><br><span class="line">bash step1.sh</span><br><span class="line"><span class="comment">#`step1.sh` won&#x27;t get the parameters in the `copnfig.sh`</span></span><br></pre></td></tr></table></figure>
<h1 id="Solvement"><a href="#Solvement" class="headerlink" title="Solvement"></a>Solvement</h1><p>There are three kinds of variable in shell scripts:</p>
<ul>
<li>local variable: difined by <code>local</code> statement, scope: the function in which it is defined</li>
<li>global variable: default, scope: the shell(not including child shells) </li>
<li>environment variable: defined by <code>export</code> command, scope: the shell(including child shells)</li>
</ul>
<p>( from<a target="_blank" rel="noopener" href="https://ningyuwhut.github.io/cn/2019/06/share-shell-variable-between-scripts">ningyuwhut’s blog</a>)</p>
<p>Figuring out these three kinds of variable helps a lot in solving the probelms above.</p>
<h1 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h1><p>I used three shell scripts to show it.</p>
<ol>
<li>child_globalconfig.sh<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#It is child_globalconfig.sh</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">#-*-coding:UTF-8-*-</span></span><br><span class="line"><span class="comment">#Author: LeafLight</span></span><br><span class="line"><span class="comment">#Date: 2022-02-07</span></span><br><span class="line">srcp=<span class="string">&quot;successful&quot;</span></span><br><span class="line"><span class="built_in">export</span> envp=<span class="string">&quot;SUCCESSFUL&quot;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<p>2.childShell.sh</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#It is childShell.sh</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">#-*-coding:UTF-8-*-</span></span><br><span class="line"><span class="comment">#Author: LeafLight</span></span><br><span class="line"><span class="comment">#Date: 2022-02-07</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;here is the child shell to show the advantage of using export to create environment parameter.&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;envp: <span class="variable">$envp</span>&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;srcp: <span class="variable">$srcp</span>&quot;</span></span><br></pre></td></tr></table></figure>

<p>3.parentShell.sh</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#It is parentShell.sh</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">#-*-coding:UTF-8-*-</span></span><br><span class="line"><span class="comment">#Author: LeafLight</span></span><br><span class="line"><span class="comment">#Date: 2022-02-07</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;---&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;here is the parent shell&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;load the config by source&quot;</span></span><br><span class="line"><span class="built_in">source</span> ./child_globalconfig.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;---&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;parent shell tries to echo the srcp and envp&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;envp: <span class="variable">$envp</span>&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;srcp: <span class="variable">$srcp</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;---&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;child shell(by bash)&quot;</span></span><br><span class="line">bash ./childShell.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;---&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;child shell(by source)&quot;</span></span><br><span class="line"><span class="built_in">source</span> ./childShell.sh</span><br></pre></td></tr></table></figure>
<p>4.Running the <code>parentShell.sh</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ bash parentShell.sh</span><br><span class="line">---</span><br><span class="line">here is the parent shell</span><br><span class="line">load the config by <span class="built_in">source</span></span><br><span class="line">---</span><br><span class="line">parent shell tries to <span class="built_in">echo</span> the srcp and envp</span><br><span class="line">envp: SUCCESSFUL</span><br><span class="line">srcp: successful</span><br><span class="line">---</span><br><span class="line">child shell(by bash)</span><br><span class="line">here is the child shell to show the advantage of using <span class="built_in">export</span> to create environment parameter.</span><br><span class="line">envp: SUCCESSFUL</span><br><span class="line">srcp: </span><br><span class="line">---</span><br><span class="line">child shell(by <span class="built_in">source</span>)</span><br><span class="line">here is the child shell to show the advantage of using <span class="built_in">export</span> to create environment parameter.</span><br><span class="line">envp: SUCCESSFUL</span><br><span class="line">srcp: successful</span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/02/07/sharement-of-paremeters-between-shell-scripts/" data-id="cl6l23unx000lbp26eywdf24q" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linux/" rel="tag">linux</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/study-note/" rel="tag">study note</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-GAN-learning" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/01/14/GAN-learning/" class="article-date">
  <time datetime="2022-01-14T06:47:22.000Z" itemprop="datePublished">2022-01-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/14/GAN-learning/">GAN_learning(PLAN)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="What-is-GAN"><a href="#What-is-GAN" class="headerlink" title="What is GAN?"></a>What is GAN?</h1><p><em>GAN</em> is the abbreviation of <em>Generative Adversarial Network</em>.It is a model of <strong>structure learning</strong></p>
<h1 id="Why-do-I-learn-GAN"><a href="#Why-do-I-learn-GAN" class="headerlink" title="Why do I learn GAN?"></a>Why do I learn GAN?</h1><p>GAN caught my attention when I read a paper about designing drugs causing desired transciptome change by <em>Bidirectional Adversarial Autoencoder(BiAA)</em>.Then I became interesting in the base the BiAA built upon,which is <em>GAN</em> and <em>Autoencoder</em>.</p>
<p><em>cited from doi:10.3389/fphar.2020.00269</em></p>
<blockquote>
<p>Gene expression profiles are useful for assessing the efficacy and side effects of drugs. In this paper, we propose a new generative model that infers drug molecules that could induce a desired change in gene expression.</p>
</blockquote>
<p>Here are the reason why I want to study further and deeper about this model</p>
<ul>
<li>The model’s structure is interesting which contains a generator and a discriminator that help with each other. </li>
<li>It is becoming more and more popular at a crazy speed.(Though many variations of it exist,it seems that no huge breakthough is made.)</li>
<li>It may help with the exploration of a brand new way of drug design.</li>
<li>The teacher Hongyi Li is so interesting.</li>
</ul>
<h1 id="Things-I-want-to-learn-about-GAN"><a href="#Things-I-want-to-learn-about-GAN" class="headerlink" title="Things I want to learn about GAN"></a>Things I want to learn about GAN</h1><ul>
<li>how it works by mathematic</li>
<li>the already-realized and promising application of it</li>
<li>how to use it in the field of medicine and how to make it more useful and dependable</li>
</ul>
<h1 id="Things-I-need-to-do"><a href="#Things-I-need-to-do" class="headerlink" title="Things I need to do"></a>Things I need to do</h1><ul>
<li>Learning the online courses by Hongyi Li</li>
<li>Read and try to understand the source code of <a target="_blank" rel="noopener" href="https://github.com/insilicomedicine/BiAAE.git">BiAA</a></li>
<li>Add BiAA to my software or come up with a better model</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/01/14/GAN-learning/" data-id="cl6l23unu0006bp26ak22bux9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PLAN/" rel="tag">PLAN</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/structure-learning/" rel="tag">structure learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hello-hexo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/01/14/hello-hexo/" class="article-date">
  <time datetime="2022-01-14T05:30:52.000Z" itemprop="datePublished">2022-01-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/14/hello-hexo/">hello hexo</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Header-1-test"><a href="#Header-1-test" class="headerlink" title="Header 1 test"></a>Header 1 test</h1><h2 id="Header-2-test"><a href="#Header-2-test" class="headerlink" title="Header 2 test"></a>Header 2 test</h2><h3 id="Header-3-test"><a href="#Header-3-test" class="headerlink" title="Header 3 test"></a>Header 3 test</h3><p><em>italic test</em></p>
<p><em>bold test</em>_</p>
<p><a href="google.com">url test(google.com-failed)</a><br><a href="www.google.com">url test(www.google.com-failed)</a><br><a target="_blank" rel="noopener" href="https://www.google.com/">url test(https://www.google.com)</a></p>
<ul>
<li>unordered</li>
<li>list</li>
<li>test</li>
</ul>
<ol>
<li>ordered</li>
<li>list </li>
<li>test</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/01/14/hello-hexo/" data-id="cl6l23unw000gbp26cgek68pq" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hello-world/" rel="tag">hello world</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-test" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/01/14/test/" class="article-date">
  <time datetime="2022-01-14T05:25:12.000Z" itemprop="datePublished">2022-01-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/14/test/">test</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/01/14/test/" data-id="cl6l23unx000nbp261v2038l2" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CMap/" rel="tag">CMap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Copy/" rel="tag">Copy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dataset/" rel="tag">Dataset</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Entropy/" rel="tag">Entropy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GrammarVAE/" rel="tag">GrammarVAE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Himmelblau-Function/" rel="tag">Himmelblau Function</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Information-theory/" rel="tag">Information theory</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MNIST/" rel="tag">MNIST</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MachineLearning/" rel="tag">MachineLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/" rel="tag">Math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Neural-Network/" rel="tag">Neural Network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Note/" rel="tag">Note</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Optimization/" rel="tag">Optimization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PLAN/" rel="tag">PLAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pokemon/" rel="tag">Pokemon</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Practice/" rel="tag">Practice</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/" rel="tag">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Source-Code/" rel="tag">Source Code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Utilities/" rel="tag">Utilities</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VAE/" rel="tag">VAE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/WorkFlow/" rel="tag">WorkFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Workflow/" rel="tag">Workflow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/functools/" rel="tag">functools</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hello-world/" rel="tag">hello world</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lambdaFunction/" rel="tag">lambdaFunction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/molecules/" rel="tag">molecules</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nltk/" rel="tag">nltk</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/note/" rel="tag">note</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/structure-learning/" rel="tag">structure learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/study-note/" rel="tag">study note</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CMap/" style="font-size: 10px;">CMap</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/Copy/" style="font-size: 10px;">Copy</a> <a href="/tags/Dataset/" style="font-size: 10px;">Dataset</a> <a href="/tags/Entropy/" style="font-size: 10px;">Entropy</a> <a href="/tags/GrammarVAE/" style="font-size: 10px;">GrammarVAE</a> <a href="/tags/Himmelblau-Function/" style="font-size: 10px;">Himmelblau Function</a> <a href="/tags/Information-theory/" style="font-size: 10px;">Information theory</a> <a href="/tags/MNIST/" style="font-size: 10px;">MNIST</a> <a href="/tags/Machine-Learning/" style="font-size: 10px;">Machine Learning</a> <a href="/tags/MachineLearning/" style="font-size: 20px;">MachineLearning</a> <a href="/tags/Math/" style="font-size: 10px;">Math</a> <a href="/tags/Neural-Network/" style="font-size: 10px;">Neural Network</a> <a href="/tags/Note/" style="font-size: 13.33px;">Note</a> <a href="/tags/Optimization/" style="font-size: 10px;">Optimization</a> <a href="/tags/PLAN/" style="font-size: 10px;">PLAN</a> <a href="/tags/Pokemon/" style="font-size: 10px;">Pokemon</a> <a href="/tags/Practice/" style="font-size: 13.33px;">Practice</a> <a href="/tags/Python/" style="font-size: 13.33px;">Python</a> <a href="/tags/Pytorch/" style="font-size: 16.67px;">Pytorch</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/Source-Code/" style="font-size: 10px;">Source Code</a> <a href="/tags/Transformer/" style="font-size: 10px;">Transformer</a> <a href="/tags/Utilities/" style="font-size: 10px;">Utilities</a> <a href="/tags/VAE/" style="font-size: 10px;">VAE</a> <a href="/tags/WorkFlow/" style="font-size: 10px;">WorkFlow</a> <a href="/tags/Workflow/" style="font-size: 13.33px;">Workflow</a> <a href="/tags/functools/" style="font-size: 10px;">functools</a> <a href="/tags/hello-world/" style="font-size: 10px;">hello world</a> <a href="/tags/lambdaFunction/" style="font-size: 10px;">lambdaFunction</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/machine-learning/" style="font-size: 16.67px;">machine learning</a> <a href="/tags/molecules/" style="font-size: 10px;">molecules</a> <a href="/tags/nltk/" style="font-size: 10px;">nltk</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/structure-learning/" style="font-size: 10px;">structure learning</a> <a href="/tags/study-note/" style="font-size: 10px;">study note</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">April 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/08/28/MathTheoryAfterAE/">Mathematical Theory after Variational Autoencoder</a>
          </li>
        
          <li>
            <a href="/2022/08/16/Pytorch-some-useful-utilities/">[Pytorch] Some useful utilities</a>
          </li>
        
          <li>
            <a href="/2022/08/16/Shallow-copy-and-deep-copy/">Shallow copy and deep copy in Python</a>
          </li>
        
          <li>
            <a href="/2022/08/09/HimmelblauOptimization_Practice_WorkFlow/">Himmelblau Function -- Optimization Practice</a>
          </li>
        
          <li>
            <a href="/2022/08/09/Pokemon_dataset_load_WorkFlow/">Custom Dataset--Pokemon dataset loading by Pytorch</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 LeafLight<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>