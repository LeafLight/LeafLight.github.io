<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Classification and MNIST dataset | LeafLight&#39;s Blog by Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="About the input:It is a famous dataset of Human-writed number pictures used for deep learning.  size of one picture: 28x28(pixels) quantity: 7000 per Number(0~9) (7kx10)  About the output:If we simply">
<meta property="og:type" content="article">
<meta property="og:title" content="Classification and MNIST dataset">
<meta property="og:url" content="http://example.com/2022/08/09/ClassificationAndMNIST/index.html">
<meta property="og:site_name" content="LeafLight&#39;s Blog by Hexo">
<meta property="og:description" content="About the input:It is a famous dataset of Human-writed number pictures used for deep learning.  size of one picture: 28x28(pixels) quantity: 7000 per Number(0~9) (7kx10)  About the output:If we simply">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://www.google.com/imgres?imgurl=https://miro.medium.com/max/1200/1*a04iKNbchayCAJ7-0QlesA.png&imgrefurl=https://medium.com/@toprak.mhmt/activation-functions-for-deep-learning-13d8b9b20e&tbnid=Zl9O5xKIlo6tvM&vet=12ahUKEwjH99qG-tb1AhXYqnIEHciXB-oQMygBegUIARDaAQ..i&docid=HgiWI3njmHtosM&w=1200&h=630&itg=1&q=Sigmoid%20function&hl=en-US&client=ubuntu&ved=2ahUKEwjH99qG-tb1AhXYqnIEHciXB-oQMygBegUIARDaAQ">
<meta property="og:image" content="https://www.google.com/imgres?imgurl=https://miro.medium.com/max/357/1*oePAhrm74RNnNEolprmTaQ.png&imgrefurl=https://medium.com/@kanchansarkar/relu-not-a-differentiable-function-why-used-in-gradient-based-optimization-7fef3a4cecec&tbnid=0UdUiZ4X2VLDiM&vet=12ahUKEwifmaTS-tb1AhWHq3IEHS10CgoQMygBegUIARC-AQ..i&docid=8NiVbpcoDLL_LM&w=357&h=278&itg=1&q=ReLU%20function&hl=en-US&client=ubuntu&ved=2ahUKEwifmaTS-tb1AhWHq3IEHS10CgoQMygBegUIARC-AQ">
<meta property="article:published_time" content="2022-08-08T17:51:44.727Z">
<meta property="article:modified_time" content="2022-08-08T17:51:44.727Z">
<meta property="article:author" content="LeafLight">
<meta property="article:tag" content="Note">
<meta property="article:tag" content="Source Code">
<meta property="article:tag" content="Neural Network">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.google.com/imgres?imgurl=https://miro.medium.com/max/1200/1*a04iKNbchayCAJ7-0QlesA.png&imgrefurl=https://medium.com/@toprak.mhmt/activation-functions-for-deep-learning-13d8b9b20e&tbnid=Zl9O5xKIlo6tvM&vet=12ahUKEwjH99qG-tb1AhXYqnIEHciXB-oQMygBegUIARDaAQ..i&docid=HgiWI3njmHtosM&w=1200&h=630&itg=1&q=Sigmoid%20function&hl=en-US&client=ubuntu&ved=2ahUKEwjH99qG-tb1AhXYqnIEHciXB-oQMygBegUIARDaAQ">
  
    <link rel="alternate" href="/atom.xml" title="LeafLight&#39;s Blog by Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.2"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">LeafLight&#39;s Blog by Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-ClassificationAndMNIST" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/08/09/ClassificationAndMNIST/" class="article-date">
  <time datetime="2022-08-08T17:51:44.727Z" itemprop="datePublished">2022-08-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/MachineLearning/">MachineLearning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Classification and MNIST dataset
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="About-the-input"><a href="#About-the-input" class="headerlink" title="About the input:"></a>About the input:</h2><p>It is a famous dataset of Human-writed number pictures used for deep learning.</p>
<ul>
<li>size of one picture: 28x28(pixels)</li>
<li>quantity: 7000 per Number(0~9) (7kx10)</li>
</ul>
<h2 id="About-the-output"><a href="#About-the-output" class="headerlink" title="About the output:"></a>About the output:</h2><p>If we simply use 0<del>9 to represent the result of prediction of our model, it results in a problem that 0</del>9 are quantitive variables. To avoid it, Here is a new method called <strong>One-Hot</strong>, which is useful in classification.</p>
<h3 id="One-Hot"><a href="#One-Hot" class="headerlink" title="One-Hot"></a>One-Hot</h3><h4 id="Representation"><a href="#Representation" class="headerlink" title="Representation"></a>Representation</h4><p>It is an special encoding method, which use a matrix(usually has an dimension of 1xn) to represent a categorical variable.</p>
<p>Here comes an example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">red = [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">blue = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>]</span><br><span class="line">yellow = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#So we can use [1,0,0,0,0,0,0,0,0,0] to represent &#x27;0&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="Evaluation-loss-calculation"><a href="#Evaluation-loss-calculation" class="headerlink" title="Evaluation(loss calculation)"></a>Evaluation(<em>loss</em> calculation)</h4><p>As to calculate the <em>loss</em> of the model, <em>Euclidean distance</em> is used(because the result of One-Hot Matrix in this model has a dimension of 10x1, which means <em>Euclidean distance</em> is proper).</p>
<p><em>here remains a question– why Euclidean distance is not proper for all kinds of data</em></p>
<p>Here comes an example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Real_label = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">Pred = [<span class="number">0.9</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.1</span>]</span><br><span class="line">loss =<span class="built_in">sum</span>([<span class="built_in">pow</span>(Real_label[i]-Pred[i],<span class="number">2</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">4</span>)]) </span><br></pre></td></tr></table></figure>

<h2 id="About-the-model"><a href="#About-the-model" class="headerlink" title="About the model:"></a>About the model:</h2><h3 id="Sigmoid-function-and-ReLU-function"><a href="#Sigmoid-function-and-ReLU-function" class="headerlink" title="Sigmoid function and ReLU function:"></a>Sigmoid function and ReLU function:</h3><ul>
<li>Sigmoid function:<br><img src="https://www.google.com/imgres?imgurl=https://miro.medium.com/max/1200/1*a04iKNbchayCAJ7-0QlesA.png&imgrefurl=https://medium.com/@toprak.mhmt/activation-functions-for-deep-learning-13d8b9b20e&tbnid=Zl9O5xKIlo6tvM&vet=12ahUKEwjH99qG-tb1AhXYqnIEHciXB-oQMygBegUIARDaAQ..i&docid=HgiWI3njmHtosM&w=1200&h=630&itg=1&q=Sigmoid%20function&hl=en-US&client=ubuntu&ved=2ahUKEwjH99qG-tb1AhXYqnIEHciXB-oQMygBegUIARDaAQ" alt="Sigmoid function"></li>
</ul>
<p>$$ h_ \theta (x) =  \frac{\mathrm{1} }{\mathrm{1} + e^- \theta^Tx }  $$</p>
<ul>
<li>ReLU function:<br><img src="https://www.google.com/imgres?imgurl=https://miro.medium.com/max/357/1*oePAhrm74RNnNEolprmTaQ.png&imgrefurl=https://medium.com/@kanchansarkar/relu-not-a-differentiable-function-why-used-in-gradient-based-optimization-7fef3a4cecec&tbnid=0UdUiZ4X2VLDiM&vet=12ahUKEwifmaTS-tb1AhWHq3IEHS10CgoQMygBegUIARC-AQ..i&docid=8NiVbpcoDLL_LM&w=357&h=278&itg=1&q=ReLU%20function&hl=en-US&client=ubuntu&ved=2ahUKEwifmaTS-tb1AhWHq3IEHS10CgoQMygBegUIARC-AQ" alt="ReLU function"></li>
</ul>
<p>$$ R(x) = max(0,x) $$</p>
<p><em>Why they are special: We don’t use linear function because linear factor is not vey qualified to deal with complex REAL-WORLD problem(Though recognizing a hand-writing number is easy for us human beings, it is difficult to teach the machine this technique.). Sigmoid F and ReLU F have a better simulation of the nerves of human beings, which have thresholds.</em> </p>
<h3 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h3><ul>
<li><p>$$ Objective = \sum (pred - Y) $$</p>
</li>
<li><p>minimize objective </p>
</li>
<li><p>for a new $$X$$</p>
<ul>
<li><p>$$[W_1,W_2,W_3]$$</p>
</li>
<li><p>$$[b_1,b_2,b_3]$$</p>
</li>
<li><p>$$pred = W_3 * \left{ W_2 \left[ W_1X + b_1\right] +b_2\right} + b_3$$</p>
</li>
<li><p>$$argmax(pred)$$</p>
</li>
</ul>
</li>
</ul>
<h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p>MNIST_utils.py </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_curve</span>(<span class="params">data</span>):</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    plt.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(data)), data, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">    plt.legend([<span class="string">&#x27;value&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;step&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;value&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_image</span>(<span class="params">img, label, name, num=(<span class="params"><span class="number">4</span>,<span class="number">4</span></span>), dataset_MU=<span class="number">0.1307</span>, dataset_SIG=<span class="number">0.3081</span></span>):</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num[<span class="number">0</span>]*num[<span class="number">1</span>]):</span><br><span class="line">        plt.subplot(num[<span class="number">0</span>], num[<span class="number">1</span>], i+<span class="number">1</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.imshow(img[i][<span class="number">0</span>]*dataset_SIG+dataset_MU, cmap=<span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&quot;&#123;&#125;:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(name, label[i].item()))</span><br><span class="line">        plt.xticks([])</span><br><span class="line">        plt.yticks([])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_hot</span>(<span class="params">label, depth=<span class="number">10</span></span>):</span></span><br><span class="line">    out = torch.zeros(label.size(<span class="number">0</span>), depth)</span><br><span class="line">    idx = torch.LongTensor(label).view(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    out.scatter_(dim=<span class="number">1</span>, index=idx, value=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<p>MNIST_train.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> MNIST_utils <span class="keyword">import</span> plot_image, plot_curve, one_hot</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">512</span></span><br><span class="line">dataset_MU = <span class="number">0.1307</span></span><br><span class="line">dataset_SIG = <span class="number">0.3081</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># step1. load dataset</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">        torchvision.datasets.MNIST(<span class="string">&#x27;mnist.data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                    transform=torchvision.transforms.Compose([</span><br><span class="line">                                        torchvision.transforms.ToTensor(),</span><br><span class="line">                                        torchvision.transforms.Normalize(</span><br><span class="line">                                            (dataset_MU,),(dataset_SIG,))</span><br><span class="line">                                        ])</span><br><span class="line">        ),</span><br><span class="line">        batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">        torchvision.datasets.MNIST(<span class="string">&#x27;mnist.data/&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                    transform=torchvision.transforms.Compose([</span><br><span class="line">                                        torchvision.transforms.ToTensor(),</span><br><span class="line">                                        torchvision.transforms.Normalize(</span><br><span class="line">                                            (dataset_MU,),(dataset_SIG,))</span><br><span class="line">                                        </span><br><span class="line">                                        ])</span><br><span class="line">        ),</span><br><span class="line">    batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">sample_x, sample_y = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))</span><br><span class="line"><span class="built_in">print</span>(sample_x.shape, sample_y.shape)</span><br><span class="line"><span class="comment">#Output[0]:torch.Size([512, 1, 28, 28]) torch.Size([512])</span></span><br><span class="line">plot_image(sample_x,sample_y,<span class="string">&#x27;image sample&#x27;</span>,num=(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment">#plot_image() is the function imported from MNIST_utils.py</span></span><br><span class="line"><span class="comment">#Output[1]:some hand-writing numbers&#x27; pictures(default 10)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># step2. Network model building</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net,self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># wx+b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">28</span>*<span class="number">28</span>, <span class="number">256</span>)</span><br><span class="line">        <span class="comment"># 28*28: the pixel size of one picture in the dataset</span></span><br><span class="line">        <span class="comment"># 256: hyper para.</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">256</span>, <span class="number">64</span>)</span><br><span class="line">        <span class="comment"># 256: the size of output of the prior layer</span></span><br><span class="line">        <span class="comment"># 64: hyper para.</span></span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line">        <span class="comment"># 64: the size of output of the prior layer</span></span><br><span class="line">        <span class="comment"># 10: the size of final output</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment">#x: [b, 1, 28, 28]</span></span><br><span class="line">        <span class="comment">#h1 = relu(w1x+b1)</span></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        <span class="comment">#h2 = relu(w2h1+b2)</span></span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        <span class="comment">#h3 = (w3h2+b3)</span></span><br><span class="line">        x = self.fc3(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"><span class="comment">#initialize the network</span></span><br><span class="line">net = Net()</span><br><span class="line"><span class="comment">#[w1, w2, w3, b1, b2, b3]</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span> )</span><br><span class="line"><span class="comment">#para. used to plot the loss_step plot</span></span><br><span class="line">train_loss = []</span><br><span class="line"><span class="comment"># step3. Training</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    <span class="comment">#3 times of traversal of the train set</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment">#print(x.shape, y.shape)</span></span><br><span class="line">        <span class="comment">#Output[2]: x:[b, 1, 28, 28], y:[512]</span></span><br><span class="line">        <span class="comment"># [b, 1, 28, 28] =&gt; [b, feature]</span></span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        <span class="comment"># =&gt;[b, 10]</span></span><br><span class="line">        out = net(x)</span><br><span class="line">        <span class="comment"># [b, 10]</span></span><br><span class="line">        y_onehot = one_hot(y)</span><br><span class="line">        <span class="comment"># loss = mse(out, y_onehot)</span></span><br><span class="line">        loss = F.mse_loss(out, y_onehot)</span><br><span class="line">        <span class="comment"># clean the gradient</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># calculate the gradient</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># update the gradient</span></span><br><span class="line">        <span class="comment">#w&#x27; = w- lr*grad</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment">#para. &#x27;loss&#x27; is a tensor object, use .item() to convert it to numpy object</span></span><br><span class="line">        train_loss.append(loss.item())</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(epoch, batch_idx, loss.item())</span><br><span class="line"><span class="comment"># we get the optimal [w1, b1, w2, b2, w3, b3]</span></span><br><span class="line">plot_curve(train_loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step4. test</span></span><br><span class="line">total_correct = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> test_loader:</span><br><span class="line">    x = x.view(x.size(<span class="number">0</span>), <span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">    out = net(x)</span><br><span class="line">    <span class="comment">#out: [b, 10] =&gt; pred: [b]</span></span><br><span class="line">    pred = out.argmax(dim=<span class="number">1</span>)</span><br><span class="line">    correct = pred.eq(y).<span class="built_in">sum</span>().<span class="built_in">float</span>()</span><br><span class="line">    total_correct += correct</span><br><span class="line"></span><br><span class="line">total_num = <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">acc = total_correct / total_num</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test acc:&#x27;</span>, acc)</span><br><span class="line"></span><br><span class="line">x, y = <span class="built_in">next</span>(<span class="built_in">iter</span>(test_loader))</span><br><span class="line">out = net(x.view(x.size(<span class="number">0</span>),<span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">pred = out.argmax(dim=<span class="number">1</span>)</span><br><span class="line">plot_image(x, pred, <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/08/09/ClassificationAndMNIST/" data-id="cl6l23uns0002bp26aj4qdlc7" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Neural-Network/" rel="tag">Neural Network</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Note/" rel="tag">Note</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Source-Code/" rel="tag">Source Code</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/08/09/hello-world/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Hello World
        
      </div>
    </a>
  
  
    <a href="/2022/08/09/EntropyAndCrossEntropy/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">An interesting understanding of Entropy and Cross Entropy</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/APH/" rel="tag">APH</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CMap/" rel="tag">CMap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Copy/" rel="tag">Copy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dataset/" rel="tag">Dataset</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Entropy/" rel="tag">Entropy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GrammarVAE/" rel="tag">GrammarVAE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Himmelblau-Function/" rel="tag">Himmelblau Function</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Information-theory/" rel="tag">Information theory</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MNIST/" rel="tag">MNIST</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MachineLearning/" rel="tag">MachineLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/" rel="tag">Math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MathModel/" rel="tag">MathModel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Neural-Network/" rel="tag">Neural Network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Note/" rel="tag">Note</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Optimization/" rel="tag">Optimization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PLAN/" rel="tag">PLAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pokemon/" rel="tag">Pokemon</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Practice/" rel="tag">Practice</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/" rel="tag">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Source-Code/" rel="tag">Source Code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Utilities/" rel="tag">Utilities</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VAE/" rel="tag">VAE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/WorkFlow/" rel="tag">WorkFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Workflow/" rel="tag">Workflow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/functools/" rel="tag">functools</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hello-world/" rel="tag">hello world</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lambdaFunction/" rel="tag">lambdaFunction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/molecules/" rel="tag">molecules</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nltk/" rel="tag">nltk</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/note/" rel="tag">note</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/structure-learning/" rel="tag">structure learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/study-note/" rel="tag">study note</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/APH/" style="font-size: 10px;">APH</a> <a href="/tags/CMap/" style="font-size: 10px;">CMap</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/Copy/" style="font-size: 10px;">Copy</a> <a href="/tags/Dataset/" style="font-size: 10px;">Dataset</a> <a href="/tags/Entropy/" style="font-size: 10px;">Entropy</a> <a href="/tags/GrammarVAE/" style="font-size: 10px;">GrammarVAE</a> <a href="/tags/Himmelblau-Function/" style="font-size: 10px;">Himmelblau Function</a> <a href="/tags/Information-theory/" style="font-size: 10px;">Information theory</a> <a href="/tags/MNIST/" style="font-size: 10px;">MNIST</a> <a href="/tags/Machine-Learning/" style="font-size: 10px;">Machine Learning</a> <a href="/tags/MachineLearning/" style="font-size: 20px;">MachineLearning</a> <a href="/tags/Math/" style="font-size: 10px;">Math</a> <a href="/tags/MathModel/" style="font-size: 10px;">MathModel</a> <a href="/tags/Neural-Network/" style="font-size: 10px;">Neural Network</a> <a href="/tags/Note/" style="font-size: 13.33px;">Note</a> <a href="/tags/Optimization/" style="font-size: 10px;">Optimization</a> <a href="/tags/PLAN/" style="font-size: 10px;">PLAN</a> <a href="/tags/Pokemon/" style="font-size: 10px;">Pokemon</a> <a href="/tags/Practice/" style="font-size: 13.33px;">Practice</a> <a href="/tags/Python/" style="font-size: 13.33px;">Python</a> <a href="/tags/Pytorch/" style="font-size: 16.67px;">Pytorch</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/Source-Code/" style="font-size: 10px;">Source Code</a> <a href="/tags/Transformer/" style="font-size: 10px;">Transformer</a> <a href="/tags/Utilities/" style="font-size: 10px;">Utilities</a> <a href="/tags/VAE/" style="font-size: 10px;">VAE</a> <a href="/tags/WorkFlow/" style="font-size: 10px;">WorkFlow</a> <a href="/tags/Workflow/" style="font-size: 13.33px;">Workflow</a> <a href="/tags/functools/" style="font-size: 10px;">functools</a> <a href="/tags/hello-world/" style="font-size: 10px;">hello world</a> <a href="/tags/lambdaFunction/" style="font-size: 10px;">lambdaFunction</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/machine-learning/" style="font-size: 16.67px;">machine learning</a> <a href="/tags/molecules/" style="font-size: 10px;">molecules</a> <a href="/tags/nltk/" style="font-size: 10px;">nltk</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/structure-learning/" style="font-size: 10px;">structure learning</a> <a href="/tags/study-note/" style="font-size: 10px;">study note</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">September 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">April 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/09/02/AHP/">Analytic Hierarchy Process</a>
          </li>
        
          <li>
            <a href="/2022/08/28/MathTheoryAfterAE/">Mathematical Theory after Variational Autoencoder</a>
          </li>
        
          <li>
            <a href="/2022/08/16/Pytorch-some-useful-utilities/">[Pytorch] Some useful utilities</a>
          </li>
        
          <li>
            <a href="/2022/08/16/Shallow-copy-and-deep-copy/">Shallow copy and deep copy in Python</a>
          </li>
        
          <li>
            <a href="/2022/08/09/HimmelblauOptimization_Practice_WorkFlow/">Himmelblau Function -- Optimization Practice</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 LeafLight<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>