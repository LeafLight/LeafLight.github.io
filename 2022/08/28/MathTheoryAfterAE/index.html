<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Mathematical Theory after Variational Autoencoder | LeafLight&#39;s Blog by Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Prior and Posterior Distribution of VAE Posterior Distribution of Encoder$$P(z|x) \propto P(z)P(x|z)$$ Prior Distribution of latent variables$$P(z)$$ the likelyhood function defining the decoder$$P(x|">
<meta property="og:type" content="article">
<meta property="og:title" content="Mathematical Theory after Variational Autoencoder">
<meta property="og:url" content="http://example.com/2022/08/28/MathTheoryAfterAE/index.html">
<meta property="og:site_name" content="LeafLight&#39;s Blog by Hexo">
<meta property="og:description" content="Prior and Posterior Distribution of VAE Posterior Distribution of Encoder$$P(z|x) \propto P(z)P(x|z)$$ Prior Distribution of latent variables$$P(z)$$ the likelyhood function defining the decoder$$P(x|">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-08-28T14:51:12.000Z">
<meta property="article:modified_time" content="2022-09-02T16:40:41.432Z">
<meta property="article:author" content="LeafLight">
<meta property="article:tag" content="MachineLearning">
<meta property="article:tag" content="VAE">
<meta property="article:tag" content="Math">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="LeafLight&#39;s Blog by Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.2"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">LeafLight&#39;s Blog by Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-MathTheoryAfterAE" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/08/28/MathTheoryAfterAE/" class="article-date">
  <time datetime="2022-08-28T14:51:12.000Z" itemprop="datePublished">2022-08-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Mathematical Theory after Variational Autoencoder
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Prior-and-Posterior-Distribution-of-VAE"><a href="#Prior-and-Posterior-Distribution-of-VAE" class="headerlink" title="Prior and Posterior Distribution of VAE"></a>Prior and Posterior Distribution of VAE</h2><ul>
<li>Posterior Distribution of Encoder<br>$$<br>P(z|x) \propto P(z)P(x|z)<br>$$</li>
<li>Prior Distribution of latent variables<br>$$<br>P(z)<br>$$</li>
<li>the likelyhood function defining the decoder<br>$$<br>P(x|z)<br>$$</li>
</ul>
<h2 id="Bayesian-Analysis"><a href="#Bayesian-Analysis" class="headerlink" title="Bayesian Analysis"></a>Bayesian Analysis</h2><h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a target="_blank" rel="noopener" href="https://www.britannica.com/science/Bayesian-analysis">Bayesian Analysis</a></li>
<li><a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2016/06/bayesian-statistics-beginners-simple-english/">Bayesian Statistics explained to Beginners in Simple English</a></li>
</ul>
<blockquote>
<p>“Bayesian statistics is a mathematical procedure that applies probabilities to statistical problems. It provides people the tools to update their beliefs in the evidence of new data.”</p>
</blockquote>
<h2 id="ELBO-loss"><a href="#ELBO-loss" class="headerlink" title="ELBO loss"></a>ELBO loss</h2><p><strong>ELBO loss</strong> consists of two parts:</p>
<ul>
<li>KL loss</li>
<li>Reconstruction loss</li>
</ul>
<p>The formular of ELBO loss:<br>$$<br>L = \min \mathbb{E}_q [\log q(z|x) - \log p(z)] - \mathbb{E}[\log p(x|z)]<br>$$</p>
<p><em>note</em>: in the loss function above, $x$ means the ground truth.</p>
<p>The KL Divergence term in the  formula above is a little different from the form widely used, which is (in continuous case):<br>$$<br>KL(P||Q) = \int_{x \in X} P(x) \log\frac{P(x)}{Q(x)}dx<br>$$<br>But it is much easier to understand the one represented in the expectation form.</p>
<h3 id="KL-Divergence"><a href="#KL-Divergence" class="headerlink" title="KL Divergence"></a>KL Divergence</h3><h4 id="reference-1"><a href="#reference-1" class="headerlink" title="reference"></a>reference</h4><ul>
<li><p><a target="_blank" rel="noopener" href="https://machinelearningmastery.com/divergence-between-probability-distributions/">how to calculate the KL divergence for machine learning</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://towardsdatascience.com/variational-autoencoder-demystified-with-pytorch-implementation-3a06bee395ed">Variational Autoencoder demystified with pytorch implementation</a></p>
</li>
</ul>
<h5 id="The-Meaning-of-KL-Divergence"><a href="#The-Meaning-of-KL-Divergence" class="headerlink" title="The Meaning of  KL Divergence"></a>The Meaning of  KL Divergence</h5><blockquote>
<p>It is often desirable to quantify the difference between probability distributions for a given random variable.</p>
<p>This can be achieved using techniques from information theory, such as the Kullback-Leibler Divergence (KL divergence), or relative entropy, and the Jensen-Shannon Divergence that provides a normalized and symmetrical version of the KL divergence. </p>
</blockquote>
<p>Here are 3 ways to measure the difference between probability distributions.</p>
<ul>
<li>KL divergence (Relative entropy)</li>
<li>JS divergence</li>
</ul>
<h5 id="Monte-Carlo-KL-Divergence"><a href="#Monte-Carlo-KL-Divergence" class="headerlink" title="Monte-Carlo KL Divergence"></a>Monte-Carlo KL Divergence</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kl_divergence</span>(<span class="params">z, mu, std</span>):</span></span><br><span class="line">	<span class="comment"># ------------------------------</span></span><br><span class="line">	<span class="comment"># Monte Carlo KL Divergence</span></span><br><span class="line">	<span class="comment"># ------------------------------</span></span><br><span class="line">	<span class="comment"># 1. two normal distributions</span></span><br><span class="line">	p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))</span><br><span class="line">	q = torch.distributions.Normal(mu, std)</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 2. log_prob</span></span><br><span class="line">	log_qzx = q.log_prob(z)</span><br><span class="line">	log_pz = p.log_prob(z)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 3. kl</span></span><br><span class="line">	kl = (log_qzx - log_pz)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 4. sum over the last dim</span></span><br><span class="line">	kl = kl.<span class="built_in">sum</span>(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> kl</span><br></pre></td></tr></table></figure>

<h3 id="Reconstruction-Loss"><a href="#Reconstruction-Loss" class="headerlink" title="Reconstruction Loss"></a>Reconstruction Loss</h3><p>The meaning of reconstruction loss is easy to understand and often implemented by MSE loss or some other criterions instead of the probability shown above.</p>
<p>It can prevent the VAE from collapsing:</p>
<blockquote>
<p>Some things may not be obvious still from this explanation. First, <strong>each</strong> image will end up with its own q. The KL term will push all the qs towards the <strong>same</strong> p (called the prior). But if all the qs, collapse to p, then the network can cheat by just mapping everything to zero and thus the VAE will collapse.</p>
<p>The reconstruction term, forces each q to be unique and spread out so that the image can be reconstructed correctly. This keeps all the qs from <strong>collapsing</strong> onto each other.</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/08/28/MathTheoryAfterAE/" data-id="cl7kpe79c0000hx26hyii1397" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MachineLearning/" rel="tag">MachineLearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Math/" rel="tag">Math</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/VAE/" rel="tag">VAE</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2022/08/16/Pytorch-some-useful-utilities/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">[Pytorch] Some useful utilities</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CMap/" rel="tag">CMap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Copy/" rel="tag">Copy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dataset/" rel="tag">Dataset</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Entropy/" rel="tag">Entropy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GrammarVAE/" rel="tag">GrammarVAE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Himmelblau-Function/" rel="tag">Himmelblau Function</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Information-theory/" rel="tag">Information theory</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MNIST/" rel="tag">MNIST</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MachineLearning/" rel="tag">MachineLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/" rel="tag">Math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Neural-Network/" rel="tag">Neural Network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Note/" rel="tag">Note</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Optimization/" rel="tag">Optimization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PLAN/" rel="tag">PLAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pokemon/" rel="tag">Pokemon</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Practice/" rel="tag">Practice</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/" rel="tag">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Source-Code/" rel="tag">Source Code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Utilities/" rel="tag">Utilities</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VAE/" rel="tag">VAE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/WorkFlow/" rel="tag">WorkFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Workflow/" rel="tag">Workflow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/functools/" rel="tag">functools</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hello-world/" rel="tag">hello world</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lambdaFunction/" rel="tag">lambdaFunction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/molecules/" rel="tag">molecules</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nltk/" rel="tag">nltk</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/note/" rel="tag">note</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/structure-learning/" rel="tag">structure learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/study-note/" rel="tag">study note</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CMap/" style="font-size: 10px;">CMap</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/Copy/" style="font-size: 10px;">Copy</a> <a href="/tags/Dataset/" style="font-size: 10px;">Dataset</a> <a href="/tags/Entropy/" style="font-size: 10px;">Entropy</a> <a href="/tags/GrammarVAE/" style="font-size: 10px;">GrammarVAE</a> <a href="/tags/Himmelblau-Function/" style="font-size: 10px;">Himmelblau Function</a> <a href="/tags/Information-theory/" style="font-size: 10px;">Information theory</a> <a href="/tags/MNIST/" style="font-size: 10px;">MNIST</a> <a href="/tags/Machine-Learning/" style="font-size: 10px;">Machine Learning</a> <a href="/tags/MachineLearning/" style="font-size: 20px;">MachineLearning</a> <a href="/tags/Math/" style="font-size: 10px;">Math</a> <a href="/tags/Neural-Network/" style="font-size: 10px;">Neural Network</a> <a href="/tags/Note/" style="font-size: 13.33px;">Note</a> <a href="/tags/Optimization/" style="font-size: 10px;">Optimization</a> <a href="/tags/PLAN/" style="font-size: 10px;">PLAN</a> <a href="/tags/Pokemon/" style="font-size: 10px;">Pokemon</a> <a href="/tags/Practice/" style="font-size: 13.33px;">Practice</a> <a href="/tags/Python/" style="font-size: 13.33px;">Python</a> <a href="/tags/Pytorch/" style="font-size: 16.67px;">Pytorch</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/Source-Code/" style="font-size: 10px;">Source Code</a> <a href="/tags/Transformer/" style="font-size: 10px;">Transformer</a> <a href="/tags/Utilities/" style="font-size: 10px;">Utilities</a> <a href="/tags/VAE/" style="font-size: 10px;">VAE</a> <a href="/tags/WorkFlow/" style="font-size: 10px;">WorkFlow</a> <a href="/tags/Workflow/" style="font-size: 13.33px;">Workflow</a> <a href="/tags/functools/" style="font-size: 10px;">functools</a> <a href="/tags/hello-world/" style="font-size: 10px;">hello world</a> <a href="/tags/lambdaFunction/" style="font-size: 10px;">lambdaFunction</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/machine-learning/" style="font-size: 16.67px;">machine learning</a> <a href="/tags/molecules/" style="font-size: 10px;">molecules</a> <a href="/tags/nltk/" style="font-size: 10px;">nltk</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/structure-learning/" style="font-size: 10px;">structure learning</a> <a href="/tags/study-note/" style="font-size: 10px;">study note</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">April 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/08/28/MathTheoryAfterAE/">Mathematical Theory after Variational Autoencoder</a>
          </li>
        
          <li>
            <a href="/2022/08/16/Pytorch-some-useful-utilities/">[Pytorch] Some useful utilities</a>
          </li>
        
          <li>
            <a href="/2022/08/16/Shallow-copy-and-deep-copy/">Shallow copy and deep copy in Python</a>
          </li>
        
          <li>
            <a href="/2022/08/09/HimmelblauOptimization_Practice_WorkFlow/">Himmelblau Function -- Optimization Practice</a>
          </li>
        
          <li>
            <a href="/2022/08/09/Pokemon_dataset_load_WorkFlow/">Custom Dataset--Pokemon dataset loading by Pytorch</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 LeafLight<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>